# Comparaison D√©taill√©e des Algorithmes ML - M√©triques RPU et Matrices de Confusion

## üìä Vue d'Ensemble

Ce document pr√©sente une analyse d√©taill√©e de la comparaison de 7 algorithmes de classification avec calcul des m√©triques **RPU (Recall, Precision, Uplift)** et g√©n√©ration de **matrices de confusion**.

## üéØ Algorithmes Compar√©s

### 1. Random Forest
- **Type** : Ensemble Learning (Bagging)
- **Principe** : Combine plusieurs arbres de d√©cision
- **Avantages** : R√©sistant au surapprentissage, g√®re bien les donn√©es non lin√©aires
- **Inconv√©nients** : Peut √™tre lent sur de grands datasets

### 2. Support Vector Machine (SVM)
- **Type** : Classificateur √† marge maximale
- **Principe** : Trouve l'hyperplan optimal pour s√©parer les classes
- **Avantages** : Efficace en haute dimension, bon avec des donn√©es non lin√©aires (kernel trick)
- **Inconv√©nients** : Sensible √† l'√©chelle des features, lent sur de grands datasets

### 3. Logistic Regression
- **Type** : Mod√®le lin√©aire probabiliste
- **Principe** : Utilise une fonction logistique pour mod√©liser la probabilit√©
- **Avantages** : Simple, interpr√©table, rapide
- **Inconv√©nients** : Assume une relation lin√©aire, sensible aux outliers

### 4. Naive Bayes
- **Type** : Classificateur probabiliste
- **Principe** : Utilise le th√©or√®me de Bayes avec l'hypoth√®se d'ind√©pendance
- **Avantages** : Tr√®s rapide, bon pour les donn√©es textuelles
- **Inconv√©nients** : Hypoth√®se d'ind√©pendance souvent viol√©e

### 5. K-Nearest Neighbors (KNN)
- **Type** : Instance-based Learning
- **Principe** : Classe selon les k voisins les plus proches
- **Avantages** : Simple, non-param√©trique, adaptatif
- **Inconv√©nients** : Lent pour les pr√©dictions, sensible √† l'√©chelle

### 6. Decision Tree
- **Type** : Arbre de d√©cision
- **Principe** : Divise r√©cursivement l'espace des features
- **Avantages** : Interpr√©table, g√®re les donn√©es non lin√©aires
- **Inconv√©nients** : Sujet au surapprentissage, instable

### 7. Gradient Boosting
- **Type** : Ensemble Learning (Boosting)
- **Principe** : Combine s√©quentiellement des mod√®les faibles
- **Avantages** : Tr√®s performant, g√®re bien les relations complexes
- **Inconv√©nients** : Peut surajuster, plus lent √† entra√Æner

## üìà M√©triques RPU Expliqu√©es

### Recall (Rappel / Sensibilit√©)

**D√©finition** : Proportion de vrais positifs correctement identifi√©s parmi tous les vrais positifs.

```
Recall = TP / (TP + FN)
```

**Interpr√©tation** :
- **Recall √©lev√©** : Le mod√®le trouve la plupart des cas positifs
- **Recall faible** : Le mod√®le manque beaucoup de cas positifs (beaucoup de faux n√©gatifs)

**Quand c'est important** :
- D√©tection de maladies (on ne veut pas manquer de cas)
- D√©tection de fraudes
- S√©curit√© (d√©tection d'intrusions)

### Precision (Pr√©cision)

**D√©finition** : Proportion de pr√©dictions positives qui sont correctes.

```
Precision = TP / (TP + FP)
```

**Interpr√©tation** :
- **Precision √©lev√©e** : Quand le mod√®le pr√©dit positif, c'est g√©n√©ralement correct
- **Precision faible** : Beaucoup de faux positifs

**Quand c'est important** :
- Filtrage de spam (on ne veut pas bloquer des emails l√©gitimes)
- Recommandations (on veut recommander des items pertinents)
- Classification de documents

### Uplift (Am√©lioration)

**D√©finition** : Am√©lioration relative de l'accuracy par rapport √† un mod√®le baseline (pr√©diction majoritaire).

```
Uplift = (Accuracy - Baseline Accuracy) / Baseline Accuracy
```

**Interpr√©tation** :
- **Uplift > 0** : Le mod√®le est meilleur que le baseline
- **Uplift √©lev√©** : Le mod√®le apporte une valeur significative
- **Uplift proche de 0** : Le mod√®le n'est gu√®re meilleur qu'une pr√©diction al√©atoire

**Exemple** :
- Baseline accuracy : 50%
- Model accuracy : 95%
- Uplift = (95% - 50%) / 50% = 90%

## üîç Matrice de Confusion

### Structure

La matrice de confusion est un tableau 2x2 (pour classification binaire) ou NxN (pour classification multi-classe) qui montre :

```
                Pr√©dit
              Positif  N√©gatif
R√©el Positif    TP      FN
     N√©gatif     FP      TN
```

### Composants

- **TP (True Positive)** : Correctement pr√©dit comme positif
  - Exemple : Un patient malade correctement identifi√© comme malade

- **TN (True Negative)** : Correctement pr√©dit comme n√©gatif
  - Exemple : Un patient sain correctement identifi√© comme sain

- **FP (False Positive)** : Incorrectement pr√©dit comme positif (Type I Error)
  - Exemple : Un patient sain incorrectement identifi√© comme malade

- **FN (False Negative)** : Incorrectement pr√©dit comme n√©gatif (Type II Error)
  - Exemple : Un patient malade incorrectement identifi√© comme sain

### Interpr√©tation

**Matrice id√©ale** :
```
[[TP,  0 ]
 [0,  TN ]]
```
Tous les cas sont correctement class√©s.

**Matrice probl√©matique** :
- **Beaucoup de FN** : Le mod√®le manque beaucoup de cas positifs (Recall faible)
- **Beaucoup de FP** : Le mod√®le fait beaucoup de fausses alertes (Precision faible)

## üìä Exemple de Comparaison D√©taill√©e

### Sc√©nario : Classification Binaire (Maladie Oui/Non)

#### R√©sultats Hypoth√©tiques

| Algorithme | Accuracy | Precision | Recall | F1-Score | Uplift | AUC-ROC |
|------------|----------|-----------|--------|----------|--------|---------|
| **Random Forest** | 0.965 | 0.965 | 0.965 | 0.965 | 0.930 | 0.999 |
| **Gradient Boosting** | 0.964 | 0.964 | 0.964 | 0.964 | 0.928 | 0.999 |
| **SVM** | 0.947 | 0.947 | 0.947 | 0.947 | 0.895 | 0.997 |
| **Logistic Regression** | 0.956 | 0.956 | 0.956 | 0.956 | 0.912 | 0.996 |
| **Naive Bayes** | 0.912 | 0.912 | 0.912 | 0.912 | 0.824 | 0.982 |
| **KNN** | 0.939 | 0.939 | 0.939 | 0.939 | 0.878 | 0.991 |
| **Decision Tree** | 0.930 | 0.930 | 0.930 | 0.930 | 0.860 | 0.987 |

### Analyse par Algorithme

#### 1. Random Forest (Meilleur)

**Matrice de Confusion** :
```
[[71,  2]   TP=71, FN=2
 [ 2, 39]]  FP=2,  TN=39
```

**Analyse** :
- ‚úÖ **Recall √©lev√© (0.965)** : Identifie 97.3% des cas positifs (71/73)
- ‚úÖ **Precision √©lev√©e (0.965)** : 97.3% des pr√©dictions positives sont correctes (71/73)
- ‚úÖ **Uplift excellent (0.930)** : 93% d'am√©lioration par rapport au baseline
- ‚úÖ **AUC-ROC excellent (0.999)** : Tr√®s bonne s√©paration des classes

**Recommandation** : **Algorithme recommand√©** pour ce probl√®me.

#### 2. Gradient Boosting

**Matrice de Confusion** :
```
[[71,  2]
 [ 2, 39]]
```

**Analyse** :
- Performance tr√®s similaire √† Random Forest
- L√©g√®rement moins performant mais tr√®s proche
- Bon compromis si Random Forest est trop lent

#### 3. SVM

**Matrice de Confusion** :
```
[[68,  5]
 [ 1, 40]]
```

**Analyse** :
- ‚ö†Ô∏è **Recall plus faible (0.947)** : Manque 5 cas positifs (68/73 = 93.2%)
- ‚úÖ **Precision tr√®s √©lev√©e (0.947)** : Peu de faux positifs (1 seul)
- **Trade-off** : Pr√©f√®re √©viter les faux positifs au d√©triment de quelques faux n√©gatifs

**Recommandation** : Utiliser si les faux positifs sont tr√®s co√ªteux.

#### 4. Logistic Regression

**Matrice de Confusion** :
```
[[70,  3]
 [ 2, 39]]
```

**Analyse** :
- Performance solide et √©quilibr√©e
- Avantage : **Tr√®s interpr√©table** (coefficients explicables)
- Rapide √† entra√Æner

**Recommandation** : Bon choix si l'interpr√©tabilit√© est importante.

#### 5. Naive Bayes

**Matrice de Confusion** :
```
[[65,  8]
 [ 2, 39]]
```

**Analyse** :
- ‚ö†Ô∏è **Recall plus faible (0.912)** : Manque 8 cas positifs (65/73 = 89%)
- Performance inf√©rieure aux autres
- Avantage : **Tr√®s rapide**

**Recommandation** : Utiliser pour des donn√©es textuelles ou si la vitesse est critique.

#### 6. KNN

**Matrice de Confusion** :
```
[[67,  6]
 [ 1, 40]]
```

**Analyse** :
- Performance moyenne
- ‚ö†Ô∏è **Recall mod√©r√© (0.939)** : Manque 6 cas positifs
- ‚úÖ **Precision √©lev√©e** : Peu de faux positifs

**Recommandation** : Utiliser si les donn√©es sont bien normalis√©es et le dataset n'est pas trop grand.

#### 7. Decision Tree

**Matrice de Confusion** :
```
[[66,  7]
 [ 1, 40]]
```

**Analyse** :
- ‚ö†Ô∏è **Recall le plus faible (0.930)** : Manque 7 cas positifs (66/73 = 90.4%)
- Avantage : **Tr√®s interpr√©table** (r√®gles explicites)
- Inconv√©nient : Peut surajuster

**Recommandation** : Utiliser si l'interpr√©tabilit√© est cruciale, mais pr√©f√©rer Random Forest.

## üéØ Recommandations par Cas d'Usage

### Cas 1 : D√©tection de Maladie (Recall Critique)

**Priorit√©** : Recall > Precision

**Choix recommand√©s** :
1. **Random Forest** (Recall: 0.965)
2. **Gradient Boosting** (Recall: 0.964)
3. **Logistic Regression** (Recall: 0.956)

**Raison** : On ne veut pas manquer de cas positifs (malades).

### Cas 2 : Filtrage de Spam (Precision Critique)

**Priorit√©** : Precision > Recall

**Choix recommand√©s** :
1. **SVM** (Precision: 0.947, peu de FP)
2. **KNN** (Precision: 0.939)
3. **Decision Tree** (Precision: 0.930)

**Raison** : On ne veut pas bloquer des emails l√©gitimes (faux positifs co√ªteux).

### Cas 3 : √âquilibre Optimal

**Priorit√©** : F1-Score (√©quilibre Recall/Precision)

**Choix recommand√©s** :
1. **Random Forest** (F1: 0.965)
2. **Gradient Boosting** (F1: 0.964)
3. **Logistic Regression** (F1: 0.956)

### Cas 4 : Interpr√©tabilit√© Requise

**Priorit√©** : Compr√©hensibilit√© du mod√®le

**Choix recommand√©s** :
1. **Logistic Regression** (coefficients explicables)
2. **Decision Tree** (r√®gles explicites)
3. **Random Forest** (importance des features)

## üìù Guide d'Interpr√©tation des Matrices de Confusion

### Classification Binaire

**Matrice parfaite** :
```
[[100,   0]   Tous les positifs corrects
 [  0, 100]]  Tous les n√©gatifs corrects
```

**Beaucoup de Faux N√©gatifs** :
```
[[ 50,  50]   Manque la moiti√© des positifs
 [  0, 100]]  Tous les n√©gatifs corrects
```
‚Üí **Probl√®me** : Recall faible, le mod√®le manque des cas positifs

**Beaucoup de Faux Positifs** :
```
[[100,   0]   Tous les positifs corrects
 [ 50,  50]]  Beaucoup de n√©gatifs mal class√©s
```
‚Üí **Probl√®me** : Precision faible, beaucoup de fausses alertes

### Classification Multi-Classe

Pour 3 classes (A, B, C) :

```
        Pr√©dit
      A    B    C
A   [50,   2,   1]   Classe A bien identifi√©e
B   [ 1,  45,   2]   Classe B bien identifi√©e
C   [ 2,   1,  48]   Classe C bien identifi√©e
```

**Interpr√©tation** :
- Diagonale principale : Pr√©dictions correctes
- Hors diagonale : Erreurs de classification
- Exemple : 2 cas de classe A mal class√©s comme B

## üîß Utilisation du Code

### Ex√©cution Rapide

```bash
cd ml-comparison
pip install -r requirements.txt
python run_comparison.py
```

### Avec Vos Donn√©es

```bash
python run_comparison.py --data votre_data.csv --target colonne_cible
```

### Via API

```bash
python api.py
# Puis utiliser les endpoints REST
```

## üìö R√©f√©rences

- **Recall** : [Wikipedia - Sensitivity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)
- **Precision** : [Wikipedia - Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)
- **Matrice de Confusion** : [scikit-learn - Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)
- **Uplift Modeling** : [Wikipedia - Uplift Modeling](https://en.wikipedia.org/wiki/Uplift_modelling)

---

## üìä R√©sultats R√©els Obtenus

**Note** : Les r√©sultats ci-dessus sont des exemples. Les performances r√©elles ont √©t√© calcul√©es sur le dataset Breast Cancer Wisconsin.

### üéØ R√©sultats R√©els (Dataset Breast Cancer - 569 √©chantillons)

| Algorithme | Accuracy | Precision | Recall | F1-Score | Uplift | AUC-ROC |
|------------|----------|-----------|--------|----------|--------|---------|
| **SVM** | **98.25%** | **98.25%** | **98.25%** | **98.25%** | **55.56%** | **99.50%** |
| **Logistic Regression** | **98.25%** | **98.25%** | **98.25%** | **98.25%** | **55.56%** | **99.54%** |
| Random Forest | 95.61% | 95.61% | 95.61% | 95.60% | 51.39% | 99.39% |
| K-Nearest Neighbors | 95.61% | 95.61% | 95.61% | 95.60% | 51.39% | 97.88% |
| Gradient Boosting | 95.61% | 95.69% | 95.61% | 95.58% | 51.39% | 99.07% |
| Naive Bayes | 92.98% | 92.98% | 92.98% | 92.98% | 47.22% | 98.68% |
| Decision Tree | 91.23% | 91.61% | 91.23% | 91.30% | 44.44% | 91.57% |

**Meilleur algorithme** : **SVM** et **Logistic Regression** (ex aequo √† 98.25%)

**Matrice de confusion - SVM** :
```
                Pr√©dit
              B√©nin  Malin
R√©el B√©nin     41      1
     Malin      1     71
```
Seulement 2 erreurs sur 114 pr√©dictions !

üìÑ **Voir le document `RESULTATS_REELS.md` pour l'analyse compl√®te des r√©sultats r√©els.**

