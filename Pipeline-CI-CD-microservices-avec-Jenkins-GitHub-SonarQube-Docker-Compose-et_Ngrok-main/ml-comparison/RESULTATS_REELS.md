# R√©sultats R√©els - Comparaison des Algorithmes ML

## üìä Donn√©es Utilis√©es

- **Dataset** : Breast Cancer Wisconsin (Diagnostic)
- **√âchantillons** : 569
- **Features** : 30 caract√©ristiques
- **Classes** : 2 (B√©nin/Malin)
- **Split** : 455 √©chantillons d'entra√Ænement / 114 √©chantillons de test
- **Baseline Accuracy** : 63.16% (classe majoritaire)

## üèÜ Classement des Algorithmes

| Rang | Algorithme | Accuracy | Precision | Recall | F1-Score | Uplift | AUC-ROC |
|------|------------|----------|-----------|--------|----------|--------|---------|
| ü•á **1** | **SVM** | **98.25%** | **98.25%** | **98.25%** | **98.25%** | **55.56%** | **99.50%** |
| ü•á **1** | **Logistic Regression** | **98.25%** | **98.25%** | **98.25%** | **98.25%** | **55.56%** | **99.54%** |
| ü•à **3** | Random Forest | 95.61% | 95.61% | 95.61% | 95.60% | 51.39% | 99.39% |
| ü•à **3** | K-Nearest Neighbors | 95.61% | 95.61% | 95.61% | 95.60% | 51.39% | 97.88% |
| ü•à **3** | Gradient Boosting | 95.61% | 95.69% | 95.61% | 95.58% | 51.39% | 99.07% |
| ü•â **6** | Naive Bayes | 92.98% | 92.98% | 92.98% | 92.98% | 47.22% | 98.68% |
| **7** | Decision Tree | 91.23% | 91.61% | 91.23% | 91.30% | 44.44% | 91.57% |

## üìà Analyse D√©taill√©e par Algorithme

### ü•á 1. SVM (Support Vector Machine) - MEILLEUR

**M√©triques** :
- **Accuracy** : 98.25%
- **Precision** : 98.25%
- **Recall** : 98.25%
- **F1-Score** : 98.25%
- **Uplift** : 55.56% (am√©lioration de 35.09 points de pourcentage)
- **AUC-ROC** : 99.50%

**Matrice de Confusion** :
```
                Pr√©dit
              B√©nin  Malin
R√©el B√©nin     41      1
     Malin      1     71
```

**Analyse** :
- ‚úÖ **Performance exceptionnelle** : Seulement 2 erreurs sur 114 pr√©dictions
- ‚úÖ **Recall excellent** : Identifie 98.8% des cas malins (71/72)
- ‚úÖ **Precision excellente** : 98.6% des pr√©dictions "malin" sont correctes (71/72)
- ‚úÖ **AUC-ROC excellent** : 99.50% - tr√®s bonne s√©paration des classes
- ‚úÖ **Stabilit√©** : CV Mean = 97.14% avec √©cart-type faible (1.79%)

**Recommandation** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **ALGORITHME RECOMMAND√â**

---

### ü•á 1. Logistic Regression - EX AEQUO

**M√©triques** :
- **Accuracy** : 98.25%
- **Precision** : 98.25%
- **Recall** : 98.25%
- **F1-Score** : 98.25%
- **Uplift** : 55.56%
- **AUC-ROC** : 99.54% (meilleur AUC-ROC de tous)

**Matrice de Confusion** :
```
                Pr√©dit
              B√©nin  Malin
R√©el B√©nin     41      1
     Malin      1     71
```

**Analyse** :
- ‚úÖ **Performance identique √† SVM** : 2 erreurs sur 114
- ‚úÖ **AUC-ROC le plus √©lev√©** : 99.54%
- ‚úÖ **Avantage majeur** : **Tr√®s interpr√©table** (coefficients explicables)
- ‚úÖ **Stabilit√©** : CV Mean = 98.02% avec √©cart-type tr√®s faible (1.28%)
- ‚úÖ **Rapidit√©** : Plus rapide √† entra√Æner que SVM

**Recommandation** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **EXCELLENT CHOIX** (surtout si interpr√©tabilit√© requise)

---

### ü•à 3. Random Forest

**M√©triques** :
- **Accuracy** : 95.61%
- **Precision** : 95.61%
- **Recall** : 95.61%
- **F1-Score** : 95.60%
- **Uplift** : 51.39%
- **AUC-ROC** : 99.39%

**Matrice de Confusion** :
```
                Pr√©dit
              B√©nin  Malin
R√©el B√©nin     39      3
     Malin      2     70
```

**Analyse** :
- ‚úÖ **Performance solide** : 5 erreurs sur 114 (4.39%)
- ‚úÖ **Recall bon** : 97.2% des cas malins identifi√©s (70/72)
- ‚ö†Ô∏è **Precision l√©g√®rement inf√©rieure** : 95.9% (70/73)
- ‚úÖ **AUC-ROC excellent** : 99.39%
- ‚úÖ **Robustesse** : R√©sistant au surapprentissage

**Recommandation** : ‚≠ê‚≠ê‚≠ê‚≠ê **BON CHOIX** pour donn√©es complexes

---

### ü•à 3. K-Nearest Neighbors (KNN)

**M√©triques** :
- **Accuracy** : 95.61%
- **Precision** : 95.61%
- **Recall** : 95.61%
- **F1-Score** : 95.60%
- **Uplift** : 51.39%
- **AUC-ROC** : 97.88%

**Matrice de Confusion** :
```
                Pr√©dit
              B√©nin  Malin
R√©el B√©nin     39      3
     Malin      2     70
```

**Analyse** :
- ‚úÖ **Performance identique √† Random Forest** : 5 erreurs
- ‚ö†Ô∏è **AUC-ROC plus faible** : 97.88% (inf√©rieur aux autres)
- ‚úÖ **Simplicit√©** : Algorithme simple et intuitif
- ‚ö†Ô∏è **Lenteur** : Plus lent pour les pr√©dictions (calcul des distances)

**Recommandation** : ‚≠ê‚≠ê‚≠ê **CHOIX MOYEN**

---

### ü•à 3. Gradient Boosting

**M√©triques** :
- **Accuracy** : 95.61%
- **Precision** : 95.69%
- **Recall** : 95.61%
- **F1-Score** : 95.58%
- **Uplift** : 51.39%
- **AUC-ROC** : 99.07%

**Matrice de Confusion** :
```
                Pr√©dit
              B√©nin  Malin
R√©el B√©nin     38      4
     Malin      1     71
```

**Analyse** :
- ‚úÖ **Performance solide** : 5 erreurs sur 114
- ‚úÖ **Precision la plus √©lev√©e du groupe** : 95.69%
- ‚úÖ **Recall excellent** : 98.6% des cas malins (71/72)
- ‚úÖ **AUC-ROC excellent** : 99.07%
- ‚ö†Ô∏è **Complexit√©** : Plus complexe √† interpr√©ter

**Recommandation** : ‚≠ê‚≠ê‚≠ê‚≠ê **BON CHOIX** pour performance maximale

---

### ü•â 6. Naive Bayes

**M√©triques** :
- **Accuracy** : 92.98%
- **Precision** : 92.98%
- **Recall** : 92.98%
- **F1-Score** : 92.98%
- **Uplift** : 47.22%
- **AUC-ROC** : 98.68%

**Matrice de Confusion** :
```
                Pr√©dit
              B√©nin  Malin
R√©el B√©nin     38      4
     Malin      4     68
```

**Analyse** :
- ‚ö†Ô∏è **Performance inf√©rieure** : 8 erreurs sur 114 (7.02%)
- ‚ö†Ô∏è **Recall plus faible** : 94.4% des cas malins (68/72)
- ‚úÖ **Avantage** : **Tr√®s rapide** √† entra√Æner et pr√©dire
- ‚úÖ **AUC-ROC bon** : 98.68%
- ‚úÖ **Stabilit√©** : CV Mean = 93.19% avec √©cart-type tr√®s faible (0.44%)

**Recommandation** : ‚≠ê‚≠ê‚≠ê **CHOIX ACCEPTABLE** si vitesse critique

---

### 7. Decision Tree

**M√©triques** :
- **Accuracy** : 91.23%
- **Precision** : 91.61%
- **Recall** : 91.23%
- **F1-Score** : 91.30%
- **Uplift** : 44.44%
- **AUC-ROC** : 91.57% (le plus faible)

**Matrice de Confusion** :
```
                Pr√©dit
              B√©nin  Malin
R√©el B√©nin     39      3
     Malin      7     65
```

**Analyse** :
- ‚ö†Ô∏è **Performance la plus faible** : 10 erreurs sur 114 (8.77%)
- ‚ö†Ô∏è **Recall plus faible** : 90.3% des cas malins (65/72)
- ‚ö†Ô∏è **AUC-ROC faible** : 91.57% (s√©paration moins bonne)
- ‚úÖ **Avantage** : **Tr√®s interpr√©table** (r√®gles explicites)
- ‚ö†Ô∏è **Surapprentissage** : Peut surajuster facilement

**Recommandation** : ‚≠ê‚≠ê **CHOIX LIMIT√â** (pr√©f√©rer Random Forest)

---

## üìä Comparaison des M√©triques RPU

### Recall (Rappel) - Capacit√© √† identifier les cas positifs

| Algorithme | Recall | Cas Malins Identifi√©s |
|------------|--------|----------------------|
| SVM | **98.25%** | 71/72 (98.6%) |
| Logistic Regression | **98.25%** | 71/72 (98.6%) |
| Gradient Boosting | 95.61% | 71/72 (98.6%) |
| Random Forest | 95.61% | 70/72 (97.2%) |
| KNN | 95.61% | 70/72 (97.2%) |
| Naive Bayes | 92.98% | 68/72 (94.4%) |
| Decision Tree | 91.23% | 65/72 (90.3%) |

**Conclusion** : SVM et Logistic Regression identifient le mieux les cas malins.

### Precision (Pr√©cision) - Fiabilit√© des pr√©dictions positives

| Algorithme | Precision | Pr√©dictions "Malin" Correctes |
|------------|-----------|------------------------------|
| Gradient Boosting | **95.69%** | 71/74 (95.9%) |
| SVM | **98.25%** | 71/72 (98.6%) |
| Logistic Regression | **98.25%** | 71/72 (98.6%) |
| Random Forest | 95.61% | 70/73 (95.9%) |
| KNN | 95.61% | 70/73 (95.9%) |
| Naive Bayes | 92.98% | 68/72 (94.4%) |
| Decision Tree | 91.61% | 65/72 (90.3%) |

**Conclusion** : SVM et Logistic Regression ont la meilleure pr√©cision.

### Uplift (Am√©lioration) - Valeur ajout√©e par rapport au baseline

| Algorithme | Uplift | Am√©lioration |
|------------|--------|--------------|
| SVM | **55.56%** | +35.09 points |
| Logistic Regression | **55.56%** | +35.09 points |
| Random Forest | 51.39% | +32.45 points |
| KNN | 51.39% | +32.45 points |
| Gradient Boosting | 51.39% | +32.45 points |
| Naive Bayes | 47.22% | +29.82 points |
| Decision Tree | 44.44% | +28.07 points |

**Conclusion** : SVM et Logistic Regression apportent la plus grande valeur.

---

## üéØ Recommandations Finales

### Pour ce Dataset (Breast Cancer)

#### ü•á Choix Optimal : **SVM ou Logistic Regression**

**SVM** si :
- Performance maximale requise
- Pas besoin d'interpr√©tabilit√©
- Temps d'entra√Ænement acceptable

**Logistic Regression** si :
- Performance maximale requise
- **Interpr√©tabilit√© importante** (coefficients explicables)
- Rapidit√© d'entra√Ænement importante
- Meilleur AUC-ROC (99.54%)

#### ü•à Alternatives Solides

- **Random Forest** : Bon compromis performance/robustesse
- **Gradient Boosting** : Si on cherche la meilleure pr√©cision possible

#### ‚ö†Ô∏è √Ä √âviter

- **Decision Tree** : Performance insuffisante, pr√©f√©rer Random Forest
- **Naive Bayes** : Performance inf√©rieure (sauf si vitesse critique)

---

## üìà Visualisations G√©n√©r√©es

Les fichiers suivants ont √©t√© g√©n√©r√©s avec les r√©sultats r√©els :

1. **real_results_confusion_matrices.png** : Matrices de confusion pour tous les algorithmes
2. **real_results_metrics_comparison.png** : Comparaison graphique des m√©triques
3. **real_results_summary.csv** : R√©sum√© au format CSV
4. **real_results_results.json** : R√©sultats d√©taill√©s au format JSON

---

## üîç Analyse des Matrices de Confusion

### Pattern d'Erreurs

**SVM & Logistic Regression** :
- 1 faux n√©gatif (cas malin pr√©dit b√©nin) ‚ö†Ô∏è
- 1 faux positif (cas b√©nin pr√©dit malin) ‚ö†Ô∏è
- **Total** : 2 erreurs (1.75%)

**Random Forest & KNN** :
- 3 faux n√©gatifs
- 2 faux positifs
- **Total** : 5 erreurs (4.39%)

**Gradient Boosting** :
- 4 faux n√©gatifs
- 1 faux positif
- **Total** : 5 erreurs (4.39%)

**Naive Bayes** :
- 4 faux n√©gatifs
- 4 faux positifs
- **Total** : 8 erreurs (7.02%)

**Decision Tree** :
- 7 faux n√©gatifs ‚ö†Ô∏è‚ö†Ô∏è
- 3 faux positifs
- **Total** : 10 erreurs (8.77%)

### Impact Clinique

Pour un probl√®me de diagnostic m√©dical :
- **Faux N√©gatifs** (FN) : **CRITIQUE** - Manquer un cas malin peut √™tre fatal
- **Faux Positifs** (FP) : Moins critique - Menera √† des tests suppl√©mentaires

**Meilleur √©quilibre** : SVM et Logistic Regression (1 FN chacun)

---

## üìù Notes Importantes

1. **Dataset** : Breast Cancer Wisconsin - Classification binaire bien √©quilibr√©e
2. **Baseline** : 63.16% (classe majoritaire)
3. **Tous les algorithmes** surpassent significativement le baseline
4. **SVM et Logistic Regression** sont ex aequo avec 98.25% d'accuracy
5. **Logistic Regression** a le meilleur AUC-ROC (99.54%)
6. **Decision Tree** est le moins performant (91.23%)

---

**Date d'ex√©cution** : 2024  
**Code utilis√©** : `run_comparison.py`  
**Dataset** : Breast Cancer Wisconsin (scikit-learn)

